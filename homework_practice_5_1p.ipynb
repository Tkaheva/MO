{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tkaheva/MO/blob/main/homework_practice_5_1p.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRkA2eOKzXtO"
      },
      "source": [
        "#  Метрики качества классификации ч.1\n",
        "\n",
        "В уроке мы разбирали матрицу ошибок и некоторые метрики, основанные на терминах матрицы ошибок. Здесь же посмотрим, как эти метрики применять на практике и что  по ним можно выяснить."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihmfQuGxzXtQ"
      },
      "source": [
        "### 1.1\n",
        "Выкачайте тренировочный датасет Titanic - train.csv - с сайта [kaggle](https://www.kaggle.com/c/titanic/data). С помощью функции pd.read_csv() загрузите данные в датафрейм. Выведите первые 20 строк и проанализируйте данные: какие колонки присутствуют (более конкретная информация по ним есть на сайте kaggle), каким образом в них обозначены данные и какие типы данных используются (используйте pandas.dtypes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV-jZFDRzXtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386a574b-faa4-4856-9aa8-20ef99376e5c"
      },
      "source": [
        "# Сначала загрузим файл с Kaggle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Вариант 1: Если файл уже есть в Google Colab\n",
        "try:\n",
        "    df = pd.read_csv('train.csv')\n",
        "    print(\"Файл найден локально\")\n",
        "except:\n",
        "    print(\"Файл не найден локально. Загружаем с GitHub...\")\n",
        "    # Альтернативный вариант: загрузка с GitHub\n",
        "    url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "    df = pd.read_csv(url)\n",
        "    print(\"Файл загружен с GitHub\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл не найден локально. Загружаем с GitHub...\n",
            "Файл загружен с GitHub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.1 Анализ данных\")\n",
        "print(\"=\"*50)\n",
        "print(\"Первые 20 строк:\")\n",
        "print(df.head(20))\n",
        "print(\"\\nИнформация о типах данных:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nРазмер датасета:\", df.shape)\n",
        "print(\"\\nКолонки:\", list(df.columns))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAXc5_Bs5Nb0",
        "outputId": "4ce87c7e-6c9f-4668-cda2-db5b119827a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.1 Анализ данных\n",
            "==================================================\n",
            "Первые 20 строк:\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0             1         0       3   \n",
            "1             2         1       1   \n",
            "2             3         1       3   \n",
            "3             4         1       1   \n",
            "4             5         0       3   \n",
            "5             6         0       3   \n",
            "6             7         0       1   \n",
            "7             8         0       3   \n",
            "8             9         1       3   \n",
            "9            10         1       2   \n",
            "10           11         1       3   \n",
            "11           12         1       1   \n",
            "12           13         0       3   \n",
            "13           14         0       3   \n",
            "14           15         0       3   \n",
            "15           16         1       2   \n",
            "16           17         0       3   \n",
            "17           18         1       2   \n",
            "18           19         0       3   \n",
            "19           20         1       3   \n",
            "\n",
            "                                                 Name     Sex   Age  SibSp  \\\n",
            "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                            Allen, Mr. William Henry    male  35.0      0   \n",
            "5                                    Moran, Mr. James    male   NaN      0   \n",
            "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
            "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
            "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
            "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
            "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
            "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
            "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
            "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
            "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
            "15                   Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
            "16                               Rice, Master. Eugene    male   2.0      4   \n",
            "17                       Williams, Mr. Charles Eugene    male   NaN      0   \n",
            "18  Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
            "19                            Masselmani, Mrs. Fatima  female   NaN      0   \n",
            "\n",
            "    Parch            Ticket     Fare Cabin Embarked  \n",
            "0       0         A/5 21171   7.2500   NaN        S  \n",
            "1       0          PC 17599  71.2833   C85        C  \n",
            "2       0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3       0            113803  53.1000  C123        S  \n",
            "4       0            373450   8.0500   NaN        S  \n",
            "5       0            330877   8.4583   NaN        Q  \n",
            "6       0             17463  51.8625   E46        S  \n",
            "7       1            349909  21.0750   NaN        S  \n",
            "8       2            347742  11.1333   NaN        S  \n",
            "9       0            237736  30.0708   NaN        C  \n",
            "10      1           PP 9549  16.7000    G6        S  \n",
            "11      0            113783  26.5500  C103        S  \n",
            "12      0         A/5. 2151   8.0500   NaN        S  \n",
            "13      5            347082  31.2750   NaN        S  \n",
            "14      0            350406   7.8542   NaN        S  \n",
            "15      0            248706  16.0000   NaN        S  \n",
            "16      1            382652  29.1250   NaN        Q  \n",
            "17      0            244373  13.0000   NaN        S  \n",
            "18      0            345763  18.0000   NaN        S  \n",
            "19      0              2649   7.2250   NaN        C  \n",
            "\n",
            "Информация о типах данных:\n",
            "PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n",
            "\n",
            "Размер датасета: (891, 12)\n",
            "\n",
            "Колонки: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W67hWJy1zXtX"
      },
      "source": [
        "### 1.2\n",
        "Проверьте, имеются ли пропущенные значения в колонках, и выведите сумму всех пропущенных значений в каждой из колонок."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrWKo-nZzXtX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ec39de-ab90-4d5a-f6de-2b646db547a8"
      },
      "source": [
        "\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Пропущенные значения по колонкам:\")\n",
        "print(missing_values[missing_values > 0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пропущенные значения по колонкам:\n",
            "Age         177\n",
            "Cabin       687\n",
            "Embarked      2\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEXNaPplzXtZ"
      },
      "source": [
        "### 1.3\n",
        "Замените все пропущенные значения колонки Age на медианы в зависимости от пола человека: т.е. если пол человека в строке с пропущенным значением \"male\", заменяете пропущенное значение возраста на медиану по всем известным возрастам мужчин, и наоборот. Выведите медианы возраста в зависимости от пола. Пропущенные значения колонок Cabin и Embarked замените на U (Unknown)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN0qq_kAzXta"
      },
      "source": [
        "Примечание: для группировки по полу можно использовать метод df.groupby(), который имеет встроенные агрегатные функции (в т.ч. для вычисления медианы).  Для установки пропущенных значений в датасете воспользуйтесь функцией df.apply()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X99uZ48yzXtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcada42-b1fc-4be4-9977-6c72d2497a78"
      },
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.3 Заполнение пропущенных значений\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Медианы возраста по полу\n",
        "male_median = df[df['Sex'] == 'male']['Age'].median()\n",
        "female_median = df[df['Sex'] == 'female']['Age'].median()\n",
        "print(f\"Медиана возраста мужчин: {male_median}\")\n",
        "print(f\"Медиана возраста женщин: {female_median}\")\n",
        "\n",
        "# Функция для заполнения возраста\n",
        "def fill_age(row):\n",
        "    if pd.isnull(row['Age']):\n",
        "        if row['Sex'] == 'male':\n",
        "            return male_median\n",
        "        else:\n",
        "            return female_median\n",
        "    return row['Age']\n",
        "\n",
        "df['Age'] = df.apply(fill_age, axis=1)\n",
        "\n",
        "# Замена пропущенных значений в Cabin и Embarked\n",
        "df['Cabin'] = df['Cabin'].fillna('U')\n",
        "df['Embarked'] = df['Embarked'].fillna('U')\n",
        "\n",
        "print(\"После заполнения пропусков:\")\n",
        "print(df.isnull().sum().sum(), \"пропусков всего\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.3 Заполнение пропущенных значений\n",
            "==================================================\n",
            "Медиана возраста мужчин: 29.0\n",
            "Медиана возраста женщин: 27.0\n",
            "После заполнения пропусков:\n",
            "0 пропусков всего\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4y7HgtRzXtd"
      },
      "source": [
        "### 1.4\n",
        "Выведите возраст пассажиров с PassengerID = [6, 20]. Убедитесь, что заполнены все пропущенные значения (воспользуйтесь функцией df.isnull() )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOb5XHuJzXte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639d5445-2ff4-4124-bf4d-c26b1ba63184"
      },
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.4 Проверка конкретных пассажиров\")\n",
        "print(\"=\"*50)\n",
        "print(\"Данные пассажиров с ID 6 и 20:\")\n",
        "print(df[df['PassengerId'].isin([6, 20])][['PassengerId', 'Age', 'Sex', 'Name']])\n",
        "print(\"\\nПроверка пропущенных значений после заполнения:\")\n",
        "print(\"Всего пропусков:\", df.isnull().sum().sum())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.4 Проверка конкретных пассажиров\n",
            "==================================================\n",
            "Данные пассажиров с ID 6 и 20:\n",
            "    PassengerId   Age     Sex                     Name\n",
            "5             6  29.0    male         Moran, Mr. James\n",
            "19           20  27.0  female  Masselmani, Mrs. Fatima\n",
            "\n",
            "Проверка пропущенных значений после заполнения:\n",
            "Всего пропусков: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ayEbWnlzXth"
      },
      "source": [
        "Так как не все классификаторы могут работать с категориальными признаками, в данном случае необходимо заменить их на числовые.\n",
        "\n",
        "Также можно было бы выделить расширенные признаки, такие как статус пассажира (Mr., Mrs., Miss., Dr., Master. и т.д.), собственный индекс билета, индекс палубы и другие, но здесь ограничимся выбором более простых признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yokvJp2dzXth"
      },
      "source": [
        "### 1.5\n",
        "В колонке Sex замените значения на 0, если пол \"male\", и на 1, если \"female\". В колонке Embarked замените параметры \"U\", \"S\", \"C\", \"Q\" на 0, 1, 2, 3 соответственно. Отбросьте колонки PassengerId, Name, Ticket, Cabin. Выведите первые 20 строк получившегося набора данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf7r1L1SzXti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5d50a1-faca-494d-eb37-bd85c129a3e5"
      },
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.5 Преобразование категориальных признаков\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Замена Sex на числовые значения\n",
        "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "# Замена Embarked на числовые значения\n",
        "embarked_mapping = {'U': 0, 'S': 1, 'C': 2, 'Q': 3}\n",
        "df['Embarked'] = df['Embarked'].map(embarked_mapping)\n",
        "\n",
        "# Удаление ненужных колонок\n",
        "df_processed = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
        "print(\"Первые 20 строк обработанного датасета:\")\n",
        "print(df_processed.head(20))\n",
        "print(\"\\nРазмер обработанного датасета:\", df_processed.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.5 Преобразование категориальных признаков\n",
            "==================================================\n",
            "Первые 20 строк обработанного датасета:\n",
            "    Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
            "0          0       3    0  22.0      1      0   7.2500         1\n",
            "1          1       1    1  38.0      1      0  71.2833         2\n",
            "2          1       3    1  26.0      0      0   7.9250         1\n",
            "3          1       1    1  35.0      1      0  53.1000         1\n",
            "4          0       3    0  35.0      0      0   8.0500         1\n",
            "5          0       3    0  29.0      0      0   8.4583         3\n",
            "6          0       1    0  54.0      0      0  51.8625         1\n",
            "7          0       3    0   2.0      3      1  21.0750         1\n",
            "8          1       3    1  27.0      0      2  11.1333         1\n",
            "9          1       2    1  14.0      1      0  30.0708         2\n",
            "10         1       3    1   4.0      1      1  16.7000         1\n",
            "11         1       1    1  58.0      0      0  26.5500         1\n",
            "12         0       3    0  20.0      0      0   8.0500         1\n",
            "13         0       3    0  39.0      1      5  31.2750         1\n",
            "14         0       3    1  14.0      0      0   7.8542         1\n",
            "15         1       2    1  55.0      0      0  16.0000         1\n",
            "16         0       3    0   2.0      4      1  29.1250         3\n",
            "17         1       2    0  29.0      0      0  13.0000         1\n",
            "18         0       3    1  31.0      1      0  18.0000         1\n",
            "19         1       3    1  27.0      0      0   7.2250         2\n",
            "\n",
            "Размер обработанного датасета: (891, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMAW08A5zXtk"
      },
      "source": [
        "### 1.6\n",
        "Приступим к построению классификаторов. **Условимся, что, если функция или объект модели имеют параметр random_state, то устанавливаем его равным 17 в каждом из случаев.**\n",
        "\n",
        "Разделите данные на тренировочный и тестовый датасеты, установив размер тестового как 0.25 (первая колонка Survived является целевой, поэтому необходимо сначала ее отделить от признаков)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld64gUCAzXtm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWs-vIXdzXtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d20043e3-e0ed-4f20-cca1-700c012229c2"
      },
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.6 Разделение данных на train/test\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "X = df_processed.drop('Survived', axis=1)\n",
        "y = df_processed['Survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=17, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Размеры выборок:\")\n",
        "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
        "print(f\"Распределение классов в y_train: {y_train.value_counts().to_dict()}\")\n",
        "print(f\"Распределение классов в y_test: {y_test.value_counts().to_dict()}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.6 Разделение данных на train/test\n",
            "==================================================\n",
            "Размеры выборок:\n",
            "X_train: (668, 7), X_test: (223, 7)\n",
            "y_train: (668,), y_test: (223,)\n",
            "Распределение классов в y_train: {0: 412, 1: 256}\n",
            "Распределение классов в y_test: {0: 137, 1: 86}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRUJb1gozXtv"
      },
      "source": [
        "### 1.7\n",
        "Обучите на полученных выборках несколько классификаторов, которые импортированы ниже.\n",
        "\n",
        "**Примечание: в методе ближайших соседей используйте количество соседей, равное 5.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1szEVSTzXtw"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pq3i9LnzXty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b126e4d6-a157-4a81-af81-7fc476658bd8"
      },
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.7 Обучение классификаторов\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=17),\n",
        "    'Logistic Regression': LogisticRegression(random_state=17, max_iter=1000)\n",
        "}\n",
        "\n",
        "trained_models = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    trained_models[name] = model\n",
        "    print(f\"{name}: обучен\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.7 Обучение классификаторов\n",
            "==================================================\n",
            "KNN: обучен\n",
            "Naive Bayes: обучен\n",
            "Decision Tree: обучен\n",
            "Logistic Regression: обучен\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv5Uy5UmzXt2"
      },
      "source": [
        "Очевидно, в этом случае использовать метрику accuracy, которую мы применяли до этого, не совсем правильно: она не даст верную оценку классификатору, потому как выживших явно меньше, чем погибших.\n",
        "\n",
        "Вспомним про такие метрики как точность и полнота. Здесь они подойдут хорошо, так как у нас имеются положительный и отрицательный классы, и определить корректно один из них может оказаться более важным ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Opt43TOIzXt3"
      },
      "source": [
        "### 1.8\n",
        "В каждом из пунктов следующего теста выберите, что важнее максимизировать: точность (precision) или полноту (recall). Выпишите ответы.\n",
        "\n",
        "1. Вероятность того, что при определенной поломке самолета он сможет долететь до пункта назначения (1 - долетел, 0 - не долетел).\n",
        "2. Предсказание, представляет ли человек опасность, по анализу психического состояния (1 - представляет опасность, 0 - не представляет опасности).\n",
        "3. Предсказание ухода клиента (1 - клиент ушел, 0 - остался).\n",
        "4. Выявление рака на основе медицинских показателей (1 - болен раком, 0 - здоров).\n",
        "5. Предсказание летальности при наблюдаемой мутации (1 - выживание, 0 - летальный исход).\n",
        "6. Определение важности происшествия для экстренных служб (1 - важно, 0 - неважно).\n",
        "7. Окупятся ли вложения в бизнес (1 - окупятся, 0 - не окупятся)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1-v6SmGzXt3"
      },
      "source": [
        "Ваш ответ:\n",
        "\n",
        "1. <br>\n",
        "2. <br>\n",
        "3. <br>\n",
        "4. <br>\n",
        "5. <br>\n",
        "6. <br>\n",
        "7. <br>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.8 Ответы на вопросы (что важнее: precision или recall)\")\n",
        "print(\"=\"*50)\n",
        "print(\"1. recall - важно не пропустить случаи, когда самолет может не долететь\")\n",
        "print(\"2. precision - важно минимизировать ложные обвинения\")\n",
        "print(\"3. recall - важно выявить всех уходящих клиентов\")\n",
        "print(\"4. recall - важно не пропустить ни одного случая рака\")\n",
        "print(\"5. recall - важно выявить все летальные случаи\")\n",
        "print(\"6. recall - важно не пропустить важные происшествия\")\n",
        "print(\"7. precision - важно не вкладывать в заведомо убыточный бизнес\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtc4GFp06sJq",
        "outputId": "ce4f995a-6e38-4ff5-e2da-99530c6283dd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.8 Ответы на вопросы (что важнее: precision или recall)\n",
            "==================================================\n",
            "1. recall - важно не пропустить случаи, когда самолет может не долететь\n",
            "2. precision - важно минимизировать ложные обвинения\n",
            "3. recall - важно выявить всех уходящих клиентов\n",
            "4. recall - важно не пропустить ни одного случая рака\n",
            "5. recall - важно выявить все летальные случаи\n",
            "6. recall - важно не пропустить важные происшествия\n",
            "7. precision - важно не вкладывать в заведомо убыточный бизнес\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqrtMi-jzXt4"
      },
      "source": [
        "### 1.9\n",
        "Определите, что важнее использовать в случае датасета Titanic: полноту или точность. Объясните, почему.\n",
        "\n",
        "### 1.10\n",
        "Для каждого классификатора выведите матрицу ошибок и самостоятельно рассчитайте метрику recall (расчеты должны присутствовать). Проверьте расчеты, воспользовавшись встроенной метрикой recall_score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ3N4TqEzXt5"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, recall_score"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVukHkOgzXt7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee9079a-5be5-42f5-f142-6ffeebafd0e3"
      },
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.9 Для датасета Titanic важнее использовать recall\")\n",
        "print(\"=\"*50)\n",
        "print(\"Обоснование: В данном контексте положительный класс - это выжившие (Survived = 1).\")\n",
        "print(\"Важнее не пропустить тех, кто мог бы выжить (максимизировать TP),\")\n",
        "print(\"чем минимизировать ложные предсказания выживания.\")\n",
        "print(\"На практике это означало бы приоритет спасения людей.\")\n",
        "print(\"\\nПример: Лучше эвакуировать несколько лишних человек (FP),\")\n",
        "print(\"чем оставить на борту кого-то, кто мог бы выжить (FN).\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.9 Для датасета Titanic важнее использовать recall\n",
            "==================================================\n",
            "Обоснование: В данном контексте положительный класс - это выжившие (Survived = 1).\n",
            "Важнее не пропустить тех, кто мог бы выжить (максимизировать TP),\n",
            "чем минимизировать ложные предсказания выживания.\n",
            "На практике это означало бы приоритет спасения людей.\n",
            "\n",
            "Пример: Лучше эвакуировать несколько лишних человек (FP),\n",
            "чем оставить на борту кого-то, кто мог бы выжить (FN).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.10 Матрицы ошибок и метрика recall\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Ручной расчет recall\n",
        "    TP = cm[1, 1]  # True Positives\n",
        "    FN = cm[1, 0]  # False Negatives\n",
        "    manual_recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "    # Расчет через sklearn\n",
        "    sklearn_recall = recall_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Матрица ошибок:\\n{cm}\")\n",
        "    print(f\"TN={cm[0,0]}, FP={cm[0,1]}, FN={cm[1,0]}, TP={cm[1,1]}\")\n",
        "    print(f\"Ручной расчет recall = TP/(TP+FN) = {TP}/({TP}+{FN}) = {manual_recall:.4f}\")\n",
        "    print(f\"Sklearn recall: {sklearn_recall:.4f}\")\n",
        "    print(f\"Совпадают: {abs(manual_recall - sklearn_recall) < 0.0001}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5NS35Ju68_l",
        "outputId": "1c54a811-a7f3-4050-ce68-294285b2c73b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.10 Матрицы ошибок и метрика recall\n",
            "==================================================\n",
            "\n",
            "KNN:\n",
            "Матрица ошибок:\n",
            "[[111  26]\n",
            " [ 33  53]]\n",
            "TN=111, FP=26, FN=33, TP=53\n",
            "Ручной расчет recall = TP/(TP+FN) = 53/(53+33) = 0.6163\n",
            "Sklearn recall: 0.6163\n",
            "Совпадают: True\n",
            "\n",
            "Naive Bayes:\n",
            "Матрица ошибок:\n",
            "[[116  21]\n",
            " [ 29  57]]\n",
            "TN=116, FP=21, FN=29, TP=57\n",
            "Ручной расчет recall = TP/(TP+FN) = 57/(57+29) = 0.6628\n",
            "Sklearn recall: 0.6628\n",
            "Совпадают: True\n",
            "\n",
            "Decision Tree:\n",
            "Матрица ошибок:\n",
            "[[121  16]\n",
            " [ 31  55]]\n",
            "TN=121, FP=16, FN=31, TP=55\n",
            "Ручной расчет recall = TP/(TP+FN) = 55/(55+31) = 0.6395\n",
            "Sklearn recall: 0.6395\n",
            "Совпадают: True\n",
            "\n",
            "Logistic Regression:\n",
            "Матрица ошибок:\n",
            "[[113  24]\n",
            " [ 29  57]]\n",
            "TN=113, FP=24, FN=29, TP=57\n",
            "Ручной расчет recall = TP/(TP+FN) = 57/(57+29) = 0.6628\n",
            "Sklearn recall: 0.6628\n",
            "Совпадают: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvz-MxztzXt8"
      },
      "source": [
        "### 1.11\n",
        "Выберите ту модель, на которой метрика recall давала лучший ответ, и рассчитайте для нее precision, используя встроенную функцию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUdiUwlszXt9"
      },
      "source": [
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UcVLFdUzXt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf2f5b4-fb8b-4046-ef3b-aaa89eecb67a"
      },
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1.11 Выбор лучшей модели по recall и расчет precision\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "best_model_name = None\n",
        "best_recall = 0\n",
        "recall_scores = {}\n",
        "\n",
        "# Находим модель с максимальным recall\n",
        "for name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    current_recall = recall_score(y_test, y_pred)\n",
        "    recall_scores[name] = current_recall\n",
        "    if current_recall > best_recall:\n",
        "        best_recall = current_recall\n",
        "        best_model_name = name\n",
        "\n",
        "print(\"Recall для всех моделей:\")\n",
        "for name, score in recall_scores.items():\n",
        "    print(f\"{name}: {score:.4f}\")\n",
        "\n",
        "print(f\"\\nЛучшая модель по recall: {best_model_name}\")\n",
        "print(f\"Recall лучшей модели: {best_recall:.4f}\")\n",
        "\n",
        "# Расчет precision для лучшей модели\n",
        "best_model = trained_models[best_model_name]\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred_best)\n",
        "\n",
        "print(f\"Precision лучшей модели: {precision:.4f}\")\n",
        "\n",
        "# Дополнительно выведем все метрики для лучшей модели\n",
        "print(f\"\\nПолный отчет по классификации для {best_model_name}:\")\n",
        "print(classification_report(y_test, y_pred_best))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_best):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, y_pred_best):.4f}\")\n",
        "\n",
        "# Вывод итоговой таблицы для всех моделей\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Сводная таблица метрик для всех моделей\")\n",
        "print(\"=\"*50)\n",
        "print(f\"{'Модель':<20} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-score':<10}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for name, model in trained_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f\"{name:<20} {acc:<10.4f} {prec:<10.4f} {rec:<10.4f} {f1:<10.4f}\")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "1.11 Выбор лучшей модели по recall и расчет precision\n",
            "==================================================\n",
            "Recall для всех моделей:\n",
            "KNN: 0.6163\n",
            "Naive Bayes: 0.6628\n",
            "Decision Tree: 0.6395\n",
            "Logistic Regression: 0.6628\n",
            "\n",
            "Лучшая модель по recall: Naive Bayes\n",
            "Recall лучшей модели: 0.6628\n",
            "Precision лучшей модели: 0.7308\n",
            "\n",
            "Полный отчет по классификации для Naive Bayes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.85      0.82       137\n",
            "           1       0.73      0.66      0.70        86\n",
            "\n",
            "    accuracy                           0.78       223\n",
            "   macro avg       0.77      0.75      0.76       223\n",
            "weighted avg       0.77      0.78      0.77       223\n",
            "\n",
            "Accuracy: 0.7758\n",
            "F1-score: 0.6951\n",
            "\n",
            "==================================================\n",
            "Сводная таблица метрик для всех моделей\n",
            "==================================================\n",
            "Модель               Accuracy   Precision  Recall     F1-score  \n",
            "------------------------------------------------------------\n",
            "KNN                  0.7354     0.6709     0.6163     0.6424    \n",
            "Naive Bayes          0.7758     0.7308     0.6628     0.6951    \n",
            "Decision Tree        0.7892     0.7746     0.6395     0.7006    \n",
            "Logistic Regression  0.7623     0.7037     0.6628     0.6826    \n"
          ]
        }
      ]
    }
  ]
}